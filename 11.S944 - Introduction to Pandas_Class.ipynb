{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.S944 Applied Urban Analytics - Pandas for Big Data\n",
    "\n",
    "### Libraries are prewritten pieces of code to perform different tasks.\n",
    "\n",
    "<img src=\"images/pandas.jpg\" width=\"650\" align=\"middle\">\n",
    "\n",
    "Pandas is the go-to Python library for Data Manipulation and Analysis.\n",
    "Pandas is awesome because it allows you to read data across various datatypes (including CSV, TSV, JSON, HTML etc) with huge file sizes.It has tons of different functions that make manipulating data a breeze. Some functions include merging and joining datasets as well as data cleaning by selecting and replacing columns. \n",
    "Pandas read Data into DataFrame (df), which is a two-dimensional data structure in the form of Rows and Columns. The official documentation is [here](https://dev.pandas.io/docs/user_guide/index.html).\n",
    "\n",
    "While learning to code is a long-term endeavor, this document aims to get you comfortable with running some of Panda's convenient built-in functions for data management. The following notebook is organised as follows, but <b> note that it is not a standard to query in the exact same order as this notebook when you embark on your own data later on. </b>\n",
    "\n",
    "### Contents \n",
    "* 01 Introduction to Pandas - Reading in your Data\n",
    "* 02 Inspecting and Viewing your Data\n",
    "* 03 Data Cleaning \n",
    "* 04 Merging Datasets\n",
    "* 05 Manipulating Datasets and Saving to CSV\n",
    "* 06 More Pandas using Bluebike data & Visualizing Data (Optional)\n",
    "\n",
    "\n",
    "We will be using two sets of AirBnb data (Daily and Monthly) for Massachusetts downloaded from Harvard Dataverse. \n",
    "\n",
    "Download the folder 'data' under E3 from Stellar.\n",
    "\n",
    "_Make sure the datafiles are in the **same folder or directory as this notebook file.**_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01- 01 Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using any library, we must import them into our notebook to proceed to bring into our Python environment. It is generally good practice to import all the libraries you need at the start of your notebook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries [import LIBRARYNAME as ALIAS]\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Airbnb daily data is a CSV file with information on airbnb in Massachusetts across several years. The dataset is around 1.8GB - way too large to use in Excel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data. Good to assign a variable so that you can just call the variable later on. \n",
    "# Variable here is called \"airbnb_daily\", but you could call it anything you like.\n",
    "airbnb_daily = pd.read_csv(\"Airbnb_daily.csv\") # Make sure file path is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - 01  Inspecting and Viewing your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step after loading your data into a variable as a dataframe is to always inspect your data. Sometimes, errors such as wrongly imported column names will require you to add additional arguments to rectify when reading the data. \n",
    "\n",
    "Pandas offers a variety of attributes and methods to quickly view this data. You can access them by adding a period and the attribute or method name after the data frame variable, i.e.:\n",
    "\n",
    "    df_variable.attributes\n",
    "    df_variable.method()\n",
    "    \n",
    "Make sure you pay attention to parentheses — they distinguish between an attribute (you can think about it as \"who you are\") and a method (\"an action\"), and the code won't work with or without, depending.\n",
    "\n",
    "Some essential attributes and methods for doing this are:\n",
    "\n",
    "* shape gives you dimensions\n",
    "* columns \n",
    "* index \n",
    "* value_counts()\n",
    "* values directly exposes the raw data\n",
    "* head() or tail() gives you the first or last 5 rows, by default. Changing the number argument inside gives you a specific number rows.\n",
    "\n",
    "More advanced but very useful are:\n",
    "\n",
    "* describe() gives you quick summary statistics\n",
    "* info() gives you a summary of data frame dimensions, column names and data types\n",
    "* mean(),sum(), count(), median() will also give you a quick intuition of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantly checking the shape is a good practice - especially after manipulating with rows and columns\n",
    "airbnb_daily.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking head of dataframe\n",
    "airbnb_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional arguments inside parenthesis\n",
    "airbnb_daily.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking tail of dataframe\n",
    "airbnb_daily.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about each column in your dataframe. You would want to ensure that the column is in a format that is want - e.g. Prices should be in some form of numeric format\n",
    "airbnb_daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe - will work if there is at least one numeric column\n",
    "# Generate descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values\n",
    "airbnb_daily.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - 02 Accessing specific sections of the Dataframe\n",
    "You can return a specific column via:\n",
    "\n",
    "    df_variable[\"column name\"]\n",
    "\n",
    "Return a range of rows via:\n",
    "\n",
    "    df_variable[start row : end row]\n",
    "\n",
    "    \n",
    "#### Some options to select and index rows and columns in Pandas.\n",
    "\n",
    "* .iloc - Selecting data by the row number(particular positions, will only take integers)\n",
    "* .loc - Selecting data by label or a condition\n",
    "* .idx - idxmax() returns row or column label where maximum value is located, idxmin() returns row or column label where minimum value is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_daily.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return column named 'Date'\n",
    "airbnb_daily['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns of your dataframe \n",
    "# Double Bracket Frames: Outer bracket indicates selection of column, Inner Brackets indicates a list\n",
    "airbnb_daily[['Property ID', 'Status', 'Price (USD)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUIZ: Combining selection methods - get the head as well as the columns 'Property ID' and Reservation ID' \n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out what does status mean? - Available, Blocked, Reserved, Unavailable\n",
    "airbnb_daily['Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out unique count values of each element\n",
    "airbnb_daily['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values in the column 'Date'\n",
    "airbnb_daily['Date'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_daily.head(11)[[\"Date\", \"Status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc (Positions) vs loc (Labels)\n",
    "airbnb_daily.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data and Status for the first 10 rows in the data set\n",
    "airbnb_daily.loc[0:10, [\"Date\", \"Status\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUIZ: Get Date and Price (USD) for 15000th entry\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - 01  Cleaning your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the source, datasets are often messy or incomplete, containing strange characters or null values alongside incorrect entries. Do not be deterred though - the process of cleaning is a great way to understand and gain insights on your data before you proceed to analysize them. Pandas is a great tool to utilize to clean up messy data.\n",
    "\n",
    "#### Some methods include:\n",
    "\n",
    "* isna() or isnull() to check for entries with NaN \n",
    "* dropna() to drop data that are NaN\n",
    "* dropna(axis=1) to drop columns\n",
    "* fillna(x) to fill all the NaN with X, any number that you choose e.g. the mean \n",
    "* replace()\n",
    "* astype() to change datatype of specific column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns using df.drop - note the argument of inplace=True!\n",
    "airbnb_daily.drop(columns= ['Price (Native)', 'Currency Native', 'HomeAway Property ID', 'Airbnb Property ID'], inplace=True)\n",
    "airbnb_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns \n",
    "airbnb_daily = airbnb_daily.rename(columns={\"Price (USD)\": \"Price\", \"Property ID\":\"Property_ID\", \"Booked Date\":\"Booked_Date\", \"Reservation ID\":\"Reservation_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_daily['Date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to datetime format - a unique format in Pandas that allow us to manipulate time series based operation on the dates\n",
    "airbnb_daily['Date']=pd.to_datetime(airbnb_daily['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_daily['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only data for Year 2018\n",
    "airbnb_sub = (airbnb_daily['Date'] >= '2018-01-01') & (airbnb_daily['Date'] <= '2018-12-31')\n",
    "daily_2018 = airbnb_daily.loc[airbnb_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz: check the shape of daily_2018\n",
    "daily_2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz: check the head and tail of daily_2018\n",
    "daily_2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz: check the mean of column 'price'. Hint: df['column'].method()\n",
    "daily_2018['Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_2018['Date'].min(), daily_2018['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure my data is clean\n",
    "print('There are', daily_2018['Date'].nunique(), 'days and', daily_2018['Reservation_ID'].nunique(), 'unique listings in the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the most expensive and cheapest apartment listed in 2018\n",
    "daily_2018[daily_2018['Price']==daily_2018['Price'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_2018[daily_2018['Price']==daily_2018['Price'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Replace outliers which may be incorrect data, find by slicing methods (loc and iloc)\n",
    "daily_2018.loc[daily_2018['Property_ID'] == 'ha-7250451']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_2018['Price'].replace(['20000.0'],600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again for any other possible outliers\n",
    "daily_2018.sort_values(by='Price', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_2018['Price'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply replacing Prices below 40 and above 2000 per day with the median price of the dataset \n",
    "# There is a flaw with doing so before throwing out all the outliers, but for quick demonstration purposes we will work with this\n",
    "\n",
    "mask = (daily_2018['Price']>= 4000) | (daily_2018['Price'] <= 40)\n",
    "daily_2018.loc[mask] = 125\n",
    "daily_2018.sort_values(by='Price', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_2018['Price'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_2018['Price'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 - 01 Merging Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main ways of combining DataFrames together (Merge, Join, Concat): \n",
    "* pd.merge - Merging based on columns or indexes (with default behaviour joining on columns)\n",
    "* df.join - Joining based on columns or indexes, similiar to Merge (with default behaviour joining on indexes)\n",
    "* pd.concat - Concating your DataFrames Vertically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the airbnb_daily dataset was interesting, it lacked several information that would be helpful later on ,such as the Latitude and Longitude for each property. We can thus utilise another dataset, airbnb_monthly, that has more information and when joined together, will give us a more comprehensive idea of the airbnb scenario in Massachusetts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the airbnb_monthly dataset\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first and last 10 rows of the data\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the columns in the data\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we dont need, leaving only\n",
    "#['Property ID', 'Property Type', 'Listing Type', 'Bedrooms','Reporting Month', 'Occupancy Rate', 'Revenue (USD)','Number of Reservations', 'Reservation Days', 'Available Days',\n",
    "#'Blocked Days', 'Country', 'State', 'City', 'Zipcode', 'Neighborhood','Latitude', 'Longitude']\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the Shape\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the information\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to datetime format\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data only for the year of 2018\n",
    "####YOUR CODE HERE####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge = monthly_2018.loc[monthly_2018['City']=='Cambridge']\n",
    "cambridge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure dataset is left with cambridge city\n",
    "cambridge['Zipcode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_2018.loc[daily_2018['Property_ID'] == 'ab-10010212'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge_joined = daily_2018.merge(cambridge[['Property ID', 'Zipcode', 'Latitude', 'Longitude']], left_on=\"Property_ID\", right_on=\"Property ID\")\n",
    "cambridge_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge_joined= cambridge_joined.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge_joined.loc[cambridge_joined['Property_ID'] == 'ab-10010212'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to Data Dictionary A = Available,  B = Blocked,  R = Reserved, U = Unavailable\n",
    "cambridge_joined['Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge_joined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge_joined.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby( ) splits the data into different groups depending on a variable of your choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the total number of entries per property in 2018\n",
    "cambridge_joined.groupby(['Property_ID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the total amount earned by each Property throughout the entire year?\n",
    "cambridge_joined[cambridge_joined['Status'] == 'B'].groupby('Property_ID')['Price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the highest amount earned by the property\n",
    "cambridge_joined[cambridge_joined['Status'] == 'B'].groupby('Property_ID')['Price'].sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out which property earned the highest\n",
    "cambridge_joined[cambridge_joined['Status'] == 'B'].groupby('Property_ID')['Price'].sum().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge_joined.loc[cambridge_joined['Property_ID']== 'ha-4918992']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 Saving to CSV (Or other formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Available = cambridge_joined.loc[cambridge_joined['Status'] == 'A' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Csv\n",
    "Available.to_csv('Available_airbnb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - 01 More Pandas - Bluebike Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from Bluebikes Website <br>\n",
    "https://s3.amazonaws.com/hubway-data/index.html <br>\n",
    "https://www.bluebikes.com/system-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and then read in your data\n",
    "stations_info = pd.read_csv(\"Hubway_Stations_as_of_July_2017.csv\")\n",
    "stations_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here start station = boardings and end station = alightings\n",
    "trips_sept = pd.read_csv(r\"201909-bluebikes-tripdata.csv\")\n",
    "trips_sept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_sept.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out boardings\n",
    "boardings = trips_sept['start station name'].value_counts()\n",
    "print(boardings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out alightings\n",
    "alightings = trips_sept['end station name'].value_counts()\n",
    "print(alightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to Datetime format\n",
    "trips_sept['date']=pd.to_datetime(trips_sept['starttime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a week's worth of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking 2nd week of September from 9-15th September as 2nd September is a Public Holiday (Labor Day)\n",
    "# Trips_sub = trips_sept.loc['2019-09-09':'2019-09-15']\n",
    "\n",
    "secondwk = (trips_sept['date'] >= '2019-09-09') & ( trips_sept['date'] <= '2019-09-15')\n",
    "trips_sub = trips_sept.loc[secondwk]\n",
    "\n",
    "trips_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boardings_week = trips_sub['start station name'].value_counts()\n",
    "boardings_week = boardings_week.to_frame(name='boarding_counts').reset_index()\n",
    "boardings_week = boardings_week.rename(columns= {'index': 'Station'}) \n",
    "boardings_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alightings_week = trips_sub['end station name'].value_counts()\n",
    "alightings_week = alightings_week.to_frame(name='alightings_counts').reset_index()\n",
    "alightings_week = alightings_week.rename(columns= {'index': 'Station'}) \n",
    "alightings_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 58 stations in cambridge\n",
    "stations = pd.merge(stations_info, boardings_week, how='inner', on='Station')\n",
    "stations2 = pd.merge(stations, alightings_week, how='inner', on = 'Station')\n",
    "cambridge_stations = stations2.loc[stations2['Municipality']=='Cambridge']\n",
    "cambridge_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Csv\n",
    "cambridge_stations.to_csv('cambridge_stations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - 02 Visualizing with  Matplotlib (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is a visualiation library in Python that allows you to visualize huge amounts of data by ploting things like line, bar, scatter plot, histogram etc quickly.\n",
    "Sample plots [here](https://matplotlib.org/tutorials/introductory/sample_plots.html#sphx-glr-tutorials-introductory-sample-plots-py).You can right click and save the image locally after it is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# magic function to ensure that your plots are rendered in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambridge_stations.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matplotlib's pyplot is the library that Pandas use in their plot function. Pandas' plot is only a convenient shortcut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame.plot - https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.plot.html\n",
    "cambridge_stations.plot(kind='scatter',x='boarding_counts',y='alightings_counts',color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting scatter plot with matplotlib\n",
    "x = cambridge_stations['boarding_counts']\n",
    "y = cambridge_stations['alightings_counts']\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,y, 'o', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting bar chart with matplotlib\n",
    "x = cambridge_stations['boarding_counts']\n",
    "y = cambridge_stations['alightings_counts']\n",
    "\n",
    "ax = cambridge_stations.plot(kind='bar',x='Station ID',y='boarding_counts',color='blue', fontsize = 30, figsize=(40,10))\n",
    "ax.legend(fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(cambridge_stations['boarding_counts']))) \n",
    "width = 0.25 \n",
    "\n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(40,10))\n",
    "\n",
    "# Create a bar with boarding_counts, in position pos,\n",
    "plt.bar(pos, cambridge_stations['boarding_counts'], width, alpha=0.5, color='#FFC300') \n",
    "     \n",
    "# Create a bar with alightings_counts in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], cambridge_stations['alightings_counts'], width, alpha=0.5, color='#FF5733') \n",
    "    \n",
    "# Set the position of the x-ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "ax.set_xticklabels(cambridge_stations['Station ID'], fontsize = 24)\n",
    "ax.yaxis.set_tick_params(labelsize=24)\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.ylim([0, max(cambridge_stations['boarding_counts'] + cambridge_stations['alightings_counts'])])\n",
    "\n",
    "# Rotate Station Names for legibility\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['Boardings', 'Alightings'], loc='upper left', fontsize = 40)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
